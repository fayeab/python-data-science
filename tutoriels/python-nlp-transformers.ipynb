{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous disposons plusieurs modèles pour traiter les données séquentielles. Ce type de modèle permet d'effectuer des tâches comme :\n",
    "* Traduction automatique qui traduit une séquence d'une langue donnée dans une autre\n",
    "* Sous-titrage d'images\n",
    "* Résumé de textes\n",
    "* ..\n",
    "\n",
    "Plusieurs types d'architecture de réseaux ont été développés pour répondre à ces problématiques :\n",
    "* Les réseaux récurrents (RNN)\n",
    "* Long Short-Term Memory (LSTM)\n",
    "* Gated Recurent Unit (GRU)\n",
    "* ...\n",
    "\n",
    "Ils sont essentiellement composés de deux parties\n",
    "* Encodeur : fournit une représentation vectorielle de la séquence\n",
    "* Décodeur : retourne une séquence à partir de la représentation vectorielle reçue de l'encodeur\n",
    "\n",
    "Ces modèles ont des points faibles :\n",
    "* Propagation et amplification des erreurs\n",
    "* Explosion ou contraction du gradient\n",
    "* ...\n",
    "\n",
    "Les chercheurs de Google ont proposé les `Transformers` pour corriger les faiblesses de ces réseaux. C'est un modèle basé sur le [mécanisme d'attention](python-nlp-mecanisme-attention.ipynb). Il ne contient pas de récurrence (pas de convolution aussi). Ce qui représente une différence fondamentale comparée aux modèles cités ci-dessus qui utilisent des réseaux récurrents. Cependant il a hérité leur configuration `Encoder - Decoder`. Du fait de l'absence de récurrence, les transformers offrent une meilleure parallélisation donc une réduction du temps d'entraînement.\n",
    "\n",
    "<img src=\"images/transformers/transformers.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie Encodage\n",
    "\n",
    "La partie `encodage` est composée d'une pile de plusieurs encodeurs (6 dans l'article original).\n",
    "\n",
    "Les encodeurs possèdent la même architecture mais ne partagent pas leurs poids :\n",
    "\n",
    "Chaque encodeur est formée d'une couche bidirectionnelle de Self-attention suivie d'une couche feed-forward. \n",
    "\n",
    "Le premier encodeur reçoit l'embedding de l'input. Pour le reste des encodeurs, la sortie de l'un constitue l'entrée de l'autre. L'attention permet de tenir compte du contexte d’un mot.\n",
    "\n",
    "<img src=\"images/transformers/encoder.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie Décodage\n",
    "\n",
    " La partie `décodage` est composée d'une pile plusieurs décodeurs (6 dans l'article original).\n",
    "\n",
    "Les décodeurs possèdent la même architecture mais ne partagent pas leurs poids :\n",
    "Chaque décodeur est formé :\n",
    "* Une couche unidirectionnelle de Self-attention   \n",
    "* Une couche intermédiaire : elle permet au décodeur de se focaliser sur la séquence d'entrée et sa représentation  \n",
    "* Une couche feed-forward.\n",
    "\n",
    "La sortie du dernier encodeur est l'entrée de tous les décodeurs.\n",
    "\n",
    "<img src=\"images/transformers/decoder.png\" width=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional encoding\n",
    "\n",
    "Comme on l'a dit plus haut, les transformers n'utilisent pas de récurrence. Cela peut potentiellement poser des problèmes pour des données séquentielles du fait l'ordre des mots à un sens. Pour remédier à cela, les transformers ajoutent un vecteur à chaque embedding avec le `Positional encoding`. Ces vecteurs ont la même dimension. Le `positional encoding` est utilisé avant les étapes d'encodage et décodage.\n",
    "\n",
    "<img src=\"images/transformers/postional_encoding.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement\n",
    "\n",
    "Quelques informations relatives à l'entrainement des transformers d'après le papier original :\n",
    "* Trois types de régularisation\n",
    "    * Ajout d'une couche de normalisation\n",
    "    * Utilisation de la technique du Dropout\n",
    "    * Label Smoothing pour améliorer la précision du modèle\n",
    "* Utilisation de la méthode d'optimisation `Àdam`\n",
    "\n",
    "\n",
    "# Prédiction\n",
    "\n",
    "Le résultat du décodeur est un vecteur contenant des valeurs numériques. Pour passer de la représentation vectorielle à un mot, on utilise une couche linéaire. Celle-ci permet de projeter le vecteur issu du décodeur dans un espace dont la dimension est égale la taille du vocabulaire. Intuitivement, il s'agit donner un score à chaque mot du vocabulaire en se basant le résultat du décodeur. La dernière étape consiste à appliquer une couche `softmax` qui transforme les scores en probabilités. La sortie correspond au mot ayant la probabilité la plus élevée.\n",
    "\n",
    "<img src=\"images/transformers/prediction.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple : Traduction d'une phrase\n",
    "\n",
    "L'objectif est de montrer d'application des transformers. On utilise un modèle déja pré-entrainé pourf de la traduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I go to the lake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Illustration de l'encodage et du décodage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etape 1** : Tokeniser la phrase : convertir en tokens la sequence pour qu'elle soit au format attendu par le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de de tokens = 6\n",
      "input_ids:\n",
      "\ttensor([[   47,   631,    12,     4, 12485,     0]])\n",
      "attention_mask:\n",
      "\ttensor([[1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(sentence, return_tensors=\"pt\")\n",
    "_, nb_tokens = tokens.input_ids.shape\n",
    "print('Nombre de de tokens = {}'.format(nb_tokens))\n",
    "for key, value in tokens.items():\n",
    "    print(\"{}:\\n\\t{}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenseur pour stocker les ID des tokens décodés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_ids = tokenizer(\"<pad>\", add_special_tokens=False, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On passe les tokens à l'encodeur et au décodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token wise output: torch.Size([1, 6, 512])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(input_ids=tokens.input_ids, \n",
    "                decoder_input_ids=decoder_input_ids, \n",
    "                return_dict=True)\n",
    "print(\"Token wise output: {}\".format(outputs.encoder_last_hidden_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 6 tokens sont encodés avec vecteurs de taille 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequence = (outputs.encoder_last_hidden_state,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etape 2** : boucle for pour obtenir les logit des tokens décodés ainsi que leur ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_tokens):\n",
    "    lm_logits = model(None, \n",
    "                      encoder_outputs=encoded_sequence, \n",
    "                      decoder_input_ids=decoder_input_ids,\n",
    "                      return_dict=True).logits\n",
    "    next_decoder_input_ids = torch.argmax(lm_logits[:, -1:], axis=-1)\n",
    "    decoder_input_ids = torch.cat([decoder_input_ids, next_decoder_input_ids], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etape 3** : générer le résultats de la traduction avec les ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je vais au lac.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Traduire directement la phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Je vais au lac.\n"
     ]
    }
   ],
   "source": [
    "# Créer les ids des tokens\n",
    "input_ids = tokenizer(sentence, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Traduction de l'exemple\n",
    "output_ids = model.generate(input_ids)[0]\n",
    "\n",
    "# Décodage et affichage des résultats\n",
    "print(tokenizer.decode(output_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Références:**  \n",
    "[Original papier : Attention Is All You Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)   \n",
    "[Hugging Face Github ](https://github.com/huggingface/transformers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
